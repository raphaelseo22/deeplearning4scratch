{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "## 신경망의 예\n",
    "- 신경망 그림에서 가장 왼쪽 줄을 입력층, 맨 오른쪽 줄을 출력층, 중간줄을 은닉층이라 부름\n",
    "- 은닉층의 뉴런은 사람의 눈에 보이지 않음\n",
    "\n",
    "## 퍼셉트론 복습\n",
    "- $ y =\n",
    "\\begin{cases}\n",
    "0,\\;if\\;b + w_1x_1+ w_2x_2 \\leq0\\\\\n",
    "1,\\;if\\;b + w_1x_1+ w_2x_2>0\n",
    "\\end{cases}$\n",
    "- 여기서 b는 편향을 의미함, 편향의 입력신호는 항상 1임\n",
    "- 위의 식을 더 간결하게 표현하면\n",
    "    - $y = h(b + w_{1}x_{1} + w_{2}x_{2})$\n",
    "    - $ h(x) =\n",
    "    \\begin{cases}\n",
    "    0, \\;if\\;x\\leq0\\\\\n",
    "    1, \\;if\\;x>0\n",
    "    \\end{cases} $\n",
    "\n",
    "## 활성화 함수 (activation function) h(x)의 등장\n",
    "- 입력신호의 총합을 출력 신호로 변환하는 함수\n",
    "- 활성화 함수는 입력 신호의 총합이 활성화를 일으키는지를 정하는 역할을 함\n",
    "- 위의 식을 다시 표현하면 아래와 같음\n",
    "    - $ a = b + w_{1}x_{1} + w_{2}x_{2} $\n",
    "    - $ y = h(a) $\n",
    "- 이 책에서 뉴련과 노드는 용어는 같은 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 활성화 함수\n",
    "- 활성화 함수는 임계값을 경계로 출력이 바뀌는데 이러한 함수를 계단 함수(step function)라 부름\n",
    "- 퍼셉트론에서는 활성화 함수로 계단 함수를 이용함\n",
    "\n",
    "## 시그모이드 함수 (sigmoid function)\n",
    "-  $ h(x) = \\frac{1}{1 + exp(-x)} $\n",
    "- 위의 식에서 exp(-x)는 e^-x 를 의미하면 e는 자연상수 2.7182....의 값을 갖는다\n",
    "- 신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고, 변환된 신호를 다음 뉴런에 전달\n",
    "- 퍼셉트론과 신경망의 주된 차이는 이 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계단 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 구현은 단순하고 쉽지만, 인수 x는  실수(부동소수점)만 받아들임\n",
    "- 즉, step_function(3.0)은 되지만 넘파이 배열을 인구로 넣을 수는 없음 가령 step_function(np.array([1.0, 2.0]))은 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.  2.]\n",
      "[False  True  True]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "print(x)\n",
    "y = x > 0\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 넘파이 배열에 부등호 연산을 수행하면 배열의 원소 각각에 부등호 연산을 수행한 bool 배열이 생성됨\n",
    "- 여기서 y는 bool 배열임 , 우리가 원하는 계단 함수는 0이나 1의 int형을 출력하는 함수임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "y = y.astype(np.int64)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이처럼 넘파이 배열의 자료형을 변환할 때는 astype() 메서드를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계단 함수의 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step_function(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시그모이드 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26894142 0.73105858 0.88079708]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "print(sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 함수가 넘파이 배열도 처리해줄 수 있는 비밀은 넘파이의 브로드캐스트\n",
    "- 브로드캐스트 기능이란 넘파이 배열과 스칼라값의 연산을 넘파이 배열의 원소 각각과 스칼라값의 연산으로 바꿔 수행하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4.]\n",
      "[1.         0.5        0.33333333]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([1.0, 2.0, 3.0])\n",
    "print(1.0 + t)\n",
    "print(1.0/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 1.0)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1) # y축 값 범위 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시그모이드 함수와 계단 함수 비교\n",
    "- 차이점\n",
    "    - 두 함수의 그래프를 보고 가장 먼저 느껴지는 차이점은 매끄럼움의 차이\n",
    "    - 시그모이드 함수는 부드러운 곡선이며 입력에 따라 출력이 연속적으로 변화함\n",
    "    - 계단 함수는 0을 경계로 출력이 값자기 변화함\n",
    "    - 시그모이드 함수의 이 매끈함이 신경망 학습에서 아주 중요한 역할을 하게 됨\n",
    "    - 계단 함수가 0과 1 중 하나의 값만 돌려주는 반면 시그모이드 함수는 실수를 돌려줌\n",
    "    - 다시 말해 퍼셉트론에서는 뉴런 사이에 0 혹은 1이 흘렀다면 신경망에서는 연속적은 실수가 흐름\n",
    "- 공통점\n",
    "    - 시그모이드 함수와 계단 함수 둘 다 입력이 작을 때는 0에 가깝게 입력이 커지면 1에 가까운 값이 출력됨\n",
    "    - 계단 함수와 시그모이드 함수는 입력이 중요하면 큰 값을 출력하고 입력이 중요하지 않으면 작은 값을 출력\n",
    "    - 입력이 아무리 크거나 작어도 출력은 0과 1 사이\n",
    "    - 둘 모두 비선형 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비선형 함수\n",
    "- 신경망에서는 활성화 함수로 비선형 함수를 사용해야 함\n",
    "- 선형함수를 사용하지 않는 이유는 선형 함수를 이용하면 신경망의 층을 깊게 하는 의미가 없어지기 때문\n",
    "- 선형 함수의 문제는 층을 아무리 깊게 해도 \"은닉층이 없는 네트워크\"로도 똑같은 기능을 할 수 있다는 것\n",
    "- 예를 들어 선형 함수인 h(x) = cx를 활성화 함수로 이용한 3층 네트워크의 경우 y(x) = h(h(h(x))) 의 식으로 나타낼 수 있음\n",
    "- 이는 y(x) = c * c * c * x 처럼 곱셈을 세번 수행하지만 실은 y(x) = ax 와 같은 식 (a = c^3)\n",
    "- 즉, 은닉층이 없는 네트워크로 표현할 수 있음 그러므로 선형 함수를 이용해서는 여러 층으로 구성하는 이점을 살릴 수 없음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU 함수\n",
    "- $ h(x)=\n",
    "\\begin{cases}\n",
    "x,\\;if\\;x>0\\\\\n",
    "0,\\;if\\;x\\leq0\n",
    "\\end{cases}$\n",
    "- 최근에는 ReLU(Rectified Linear Unit)함수를 주로 이용\n",
    "- ReLU는 입력이 0을 넘으면 그 입력을 그대로 출력하고, 0 이하이면 0을 출력하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다차원 배열의 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다차원 배열\n",
    "- 다차원 배열도 기본적으로 \"숫자의 집합\"\n",
    "- 숫자가 한 줄로 늘어선 것, 직사각형으로 늘어놓은 것, N차원으로 나열하는 것을 통틀어서 다차원 배열이라 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "1\n",
      "(4,)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 1차원 배열\n",
    "A = np.array([1, 2, 3, 4])\n",
    "print(A)\n",
    "print(np.ndim(A))\n",
    "print(A.shape)\n",
    "print(A.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "2\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2차원 배열\n",
    "B = np.array([[1,2], [3,4], [5,6]])\n",
    "print(B)\n",
    "print(np.ndim(B))\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2차원 배열은 행렬이라 부르고 가로방향을 행(row), 세로방향을 열(column)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 행렬의 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2, 2)\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2], [3,4]])\n",
    "print(A.shape)\n",
    "B = np.array([[5,6], [7,8]])\n",
    "print(B.shape)\n",
    "print(np.dot(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- np.dot은  입력이 1차원 배열이면 벡터를, 2차원 배열이면 행렬 곱을 계산\n",
    "- 여기서 주의해야 할 점은 np.dot(A, B)와 np.dot(B, A)의 값이 다를 수 있음\n",
    "- 행렬의 곱셈은 피연산자의 순서가 다르면 결과도 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망에서의 행렬 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2])\n",
    "print(X.shape)\n",
    "W = np.array([[1,3,5], [2,4,6]])\n",
    "print(W.shape)\n",
    "Y = np.dot(X, W)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다차원 배열에 스칼라곱을 구해주는 np.dot 함수를 사용하명 단번에 결과 Y를 계산할 수 있음\n",
    "- 그래서 행렬의 곱으로 한꺼번에 계산해주는 기능은 신경망을 구현할 때 매우 중요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3층 신경망 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1층 첫번째 뉴런으로 가는 신호\n",
    "- $ a^1_1 = w^1_{11}x_1 + w^1_{12}x_2 + b^1_1 $\n",
    "- 여기에서 행렬의 곱을 이용하면 1층의 가중치 부분을 다음 식처럼 간소화 가능\n",
    "- $ A^1 = XW^1 + B^1 $\n",
    "- $ A = (a^1_1 \\quad a^1_2 \\quad a^1_3) $\n",
    "- $ X = (x_1 \\quad x_2) $\n",
    "- $ B^1 = (b^1_1 \\quad b^1_2 \\quad b^1_3) $\n",
    "- $ W = \\begin{pmatrix}w^1_{11}&w^1_{21}&w^1_{31}\\\\w^1_{12}&w^1_{22}&w^1_{32} \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n",
      "[0.3 0.7 1.1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1) + B1\n",
    "print(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "Z1 = sigmoid(A1)\n",
    "print(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[0.51615984 1.21402696]\n",
      "[0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "# 1층에서 2층으로 연결되는 과정\n",
    "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "print(Z1.shape)\n",
    "print(W2.shape)\n",
    "print(B2.shape)\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)\n",
    "print(A2)\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막으로 2층에서 출력층으로 신호 전달\n",
    "- 출력층의 구현도 그동안의 구현과 거의 같지만 활성화 함수만 은닉층과 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def identify_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identify_function(A3)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현 정리\n",
    "- 신경망 구현의 관례에 따라 가중치만 W1과 같이 대문자로 작성하고, 그 외 편향과 중간 결과 등은 모두 소문자로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "from operator import ne\n",
    "from tkinter import N\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network[\"W1\"] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network[\"b1\"] = np.array([0.1, 0.2, 0.3])\n",
    "    network[\"W2\"] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network[\"b2\"] = np.array([0.1, 0.2])\n",
    "    network[\"W3\"] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network[\"b3\"] = np.array([0.1, 0.2])\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network[\"W1\"], network[\"W2\"], network[\"W3\"]\n",
    "    b1, b2, b3 = network[\"b1\"], network[\"b2\"], network[\"b3\"]\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + B3\n",
    "    y = identify_function(a3)\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([0.1, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- init_network 함수는 가중치와 편향을 초기화하고 이들을 딕셔너리 변수인 network에 저장\n",
    "- 이 network에는 각층의 매개변수(가중치와 편향)를 저장\n",
    "- forward 함수는 입력 신호를 출력으로 변환하는 처리 과정을 모두 구현\n",
    "- 함수 이름이 forward인 이유는 신호가 순방향(입력에서 출력방향)으로 전달됨(순정하)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 출력층 설계하기\n",
    "- 신경망은 분류와 회귀 모두에 이용할 수 있음\n",
    "- 다만, 둘 중 어떤 문제냐에 따라 출력층에서 사용하는 활성화 함수가 달라짐\n",
    "- 일반적으로 회귀에는 항등 함수를, 분류에는 소프트맥스 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함등 함수와 소프트맥스 함수 구현하기\n",
    "- 항등함수(identify function)은 입력을 그대로 출력, 입력과 출력이 항상 같다는 의미\n",
    "- 분류에서 사용하는 소프트맥스 함수(softmax function)의 식은 다음과 같음\n",
    "- $ y_k = \\frac{exp(a_k)}{\\displaystyle\\sum_{i=1}^{n}{exp(a_i)}} $\n",
    "- $ exp(x)$ 는 $ e^x $ 을 뜻하는 지수함수(exponential funtion), e는 자연상수, n은 출력층의 뉴런 수, $y_k$는  그 중 k번쨰 출력임을 의미\n",
    "- 소프트맥스 함수의 분자는 입력 신호 $a_k$의 지수 함수, 분모는 모든 입력 신호의 지수 함수의 합으로 구성됨\n",
    "- 소프트맥스의 출력은 모든 입력 신호에서 영향을 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a)\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트맥스 함수 구현 시 주의점\n",
    "- 소프트맥스 함수는 지수 함수를 사용하기 때문에 컴퓨터로 계산시 오버플로우 문제가 발생할 가능성이 높음\n",
    "- $ y_k = \\frac{exp(a_k)}{\\displaystyle\\sum_{i=1}^{n}{exp(a_i)}} = \\frac{Cexp(a_k)}{C\\displaystyle\\sum_{i=1}^{n}{exp(a_i)}} = \\frac{exp(a_k + \\log C)}{\\displaystyle\\sum_{i=1}^{n}{exp(a_i + \\log C)}} = \\frac{exp(a_k + C^{'})}{\\displaystyle\\sum_{i=1}^{n}{exp(a_i + C^{'})}} $\n",
    "- 첫 번째 변형에서는 $C$라는 임의의 정수를 분자와 분모 양쪽에 곱함\n",
    "- 그 다음에 $C$를 지수함수 $exp()$ 안에 옮겨 $ \\log C$로 만듦\n",
    "- 마지막으로 $\\log C$를 $C^{'}$라는 새로운 기호로 바꿈\n",
    "- 위 식이 말하는 것은 소프트맥스 함수에 어떠한 정수를 더해도 값은 바뀌지 않는다는 것\n",
    "- 여기서 $C^{'}$에 어떤 값을 대입해도 상관없지만, 오버플로를 막을 목적으로는 입력 신호 중 최댓값을 이용하는 것이 일반적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[  0 -10 -20]\n",
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/gswr1sjs3pg7jdl_fq608b5m0000gp/T/ipykernel_20344/763123458.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  print(np.exp(a)/np.sum(np.exp(a))) # nan = not a number\n",
      "/var/folders/h5/gswr1sjs3pg7jdl_fq608b5m0000gp/T/ipykernel_20344/763123458.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  print(np.exp(a)/np.sum(np.exp(a))) # nan = not a number\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1010, 1000, 990])\n",
    "print(np.exp(a)/np.sum(np.exp(a))) # nan = not a number\n",
    "\n",
    "c = np.max(a)\n",
    "print(a-c)\n",
    "\n",
    "print(np.exp(a-c)/np.sum(np.exp(a-c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트맥스 함수의 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소프트맥스 함수의 출력은 0에서 1사이의 실수\n",
    "- 소프트맥스 함수의 출력 총합은 1 > 그러므로 소프트맥스 함수의 출력을 확률로 해석할 수 있음\n",
    "- 주의점으로 소프트맥스 함수를 적용하더라도 각 원소의 대소관계는 변하지 않음\n",
    "- 지수 함수 $y = exp(x)$는 단조 증가 함수이기 때문\n",
    "- 단조 증가 함수란 $a,b$가 $a \\leq b$ 일때 $f(a) \\leq f(b)$ 인 함수\n",
    "- 신경망을 이용한 분류에서는 일반적으로 가장 큰 출력을 내는 뉴런에 해당하는 클래스로만 이식\n",
    "- 소프트맥스 함수를 적용하더라도 출력이 가장 큰 뉴런의 위치는 달라지지 않음 > 결과적으로 신경망으로 분류할 때 출력층의 소프트맥스 함수는 생략해도 됨\n",
    "- 현업에서도 지수 함수 계산에 드는 자원 낭비를 줄이고자 출력층의 소프트맥스 함수를 생략하는 것이 일반적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출력층의 뉴런 수 정하기\n",
    "- 출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야함\n",
    "- 분류에서는 분류하고 싶은 클래스의 수로 설정하는 것이 일반적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨 숫자 인식\n",
    "- 기계학습과 마찬가지로 신경망도 두 단계를 거쳐 문제를 해결\n",
    "- 먼저 학습 데이터를 사용해 가중치 매개변수를 학습하고, 추론 단계에서는 앞서 학습한 매개변수를 사용하여 입력 데이터를 분류\n",
    "- 여기서 추론 과정을 신경망의 순전파(forward propagation)라고도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋\n",
    "- MNIST 데이터셋은 손글씨 숫자 이미지 집합\n",
    "- MNIST 데이터셋은 0부터 9까지의 숫자 이미지로 구성\n",
    "- 학습데이터 60,000장 시험 데이터 10,000장 준비되어 있음\n",
    "- MNIST의 이미지 데이터는 28X28 크기의 회색조 이미지(1채널)이며, 각 픽셀은 0부터 255까지의 값을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load_mnist 함수는 읽은 MNIST 데이터를 (훈련 데이터, 훈련 레이블), (시험 데이터, 시험 레이블) 형식으로 변환\n",
    "- 인수로는 normalize, flatten, one_hot_label을 받음 > 3가지 모두 bool\n",
    "- normalize는 입력 이미지의 픽셀값을 0.0 ~ 1.0 사이의 값으로 정규화할지를 정함\n",
    "- flatten은  입력 이미지를 평탄하게, 즉 1차원 배열로 만들지를 정함\n",
    "- one_hot_label은 one-hot encoding 형태로 저장할지르 정함\n",
    "- one-hot encoding이란 [0, 1, 0, 0, 0, 0] 처럼 정답을 뜻하는 원소만 1이고 나머지는 모두 0인 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('deeplearning_from_scratch--XaqxMC7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2432a05c8243b8bb4e8235326c7c3baac6b5d530a234818e0999fa6379eb8310"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
